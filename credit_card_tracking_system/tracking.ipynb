{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "37b40e2e-b931-407b-9705-c49216108b84",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import current_timestamp, lit\n",
    "from delta.tables import DeltaTable\n",
    "\n",
    "# Step 1: Initialize the Spark session\n",
    "spark = SparkSession.builder.appName(\"credit_card_scd2_tracking\").getOrCreate()\n",
    "\n",
    "# Step 2: Define the schema for SCD Type 2 with the following columns:\n",
    "scd2_columns = [\"card_id\", \"customer_id\", \"status\", \"credit_limit\", \"valid_from\", \"valid_to\", \"is_current\"]\n",
    "\n",
    "# Step 3: Define the source data (this represents the updated data)\n",
    "source_data = [\n",
    "    (101, 1, \"active\", 6000.0),  # Card upgraded (updated data in source)\n",
    "    (102, 2, \"blocked\", 10000.0)  # Card blocked (updated data in source)\n",
    "]\n",
    "source_columns = [\"card_id\", \"customer_id\", \"status\", \"credit_limit\"]\n",
    "\n",
    "# Create a DataFrame from the source data\n",
    "source_df = spark.createDataFrame(source_data, source_columns)\n",
    "\n",
    "# Step 4: Save the source data as a Delta table (if it doesn't exist already)\n",
    "source_table_name = \"incremental_load.default.credit_cards_source\"\n",
    "\n",
    "source_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(source_table_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0589a142-d177-4c6d-8af7-c4aacfa5dcdd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from delta.tables import DeltaTable\n",
    "\n",
    "# New or updated records\n",
    "upsert_data = [\n",
    "    (101, 1, \"blocked\", 6000.0),  # Updated status for card_id 101\n",
    "    (105, 5, \"active\", 8000.0)    # New card\n",
    "]\n",
    "columns = [\"card_id\", \"customer_id\", \"status\", \"credit_limit\"]\n",
    "\n",
    "upsert_df = spark.createDataFrame(upsert_data, columns)\n",
    "\n",
    "# Load the source table\n",
    "source_delta = DeltaTable.forName(spark, source_table_name)\n",
    "\n",
    "# Perform merge\n",
    "source_delta.alias(\"target\").merge(\n",
    "    upsert_df.alias(\"source\"),\n",
    "    \"target.card_id = source.card_id\"\n",
    ").whenMatchedUpdateAll() \\\n",
    " .whenNotMatchedInsertAll() \\\n",
    " .execute()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0dc8f074-184f-4329-9f05-28d9ac9c8ef1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "target_table_name = \"incremental_load.default.credit_cards_target\"\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.types import *\n",
    "if not spark.catalog.tableExists(target_table_name):\n",
    "    # If the table doesn't exist, create it (initialize the table with the defined schema)\n",
    "    scd2_schema = StructType([\n",
    "    StructField(\"card_id\", IntegerType(), True),\n",
    "    StructField(\"customer_id\", IntegerType(), True),\n",
    "    StructField(\"status\", StringType(), True),\n",
    "    StructField(\"credit_limit\", DoubleType(), True),\n",
    "    StructField(\"valid_from\", TimestampType(), True),\n",
    "    StructField(\"valid_to\", TimestampType(), True),\n",
    "    StructField(\"is_current\", BooleanType(), True)\n",
    "    ])\n",
    "\n",
    "    empty_df = spark.createDataFrame([], scd2_schema)\n",
    "\n",
    "    # Save as Delta table\n",
    "    empty_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(target_table_name)\n",
    "else:\n",
    "    print(f\"Table {target_table_name} already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "046fd20a-0ba8-44c3-a24d-2a4d396e4b66",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "delta_table = DeltaTable.forName(spark, target_table_name)\n",
    "delta_table.alias(\"t\").merge(\n",
    "    source_df.alias(\"s\"),\n",
    "    \"t.card_id = s.card_id AND t.is_current = true\"  # Matching records with active status\n",
    ").whenMatchedUpdate(\n",
    "    condition=\"t.status != s.status OR t.credit_limit != s.credit_limit\",  # If the data has changed\n",
    "    set={\n",
    "        \"valid_to\": current_timestamp(),  # Expire the old record\n",
    "        \"is_current\": lit(False)  # Mark as not current\n",
    "    }\n",
    ").execute()\n",
    "display(delta_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5a96c5ef-63f1-4852-8960-7fa0ec0478cb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "delta_table.alias(\"t\").merge(\n",
    "    source_df.alias(\"s\"),\n",
    "    \"t.card_id = s.card_id AND t.is_current = false\"  # Only insert when current is false (i.e., history has expired)\n",
    ").whenNotMatchedInsert(\n",
    "    values={\n",
    "        \"card_id\": \"s.card_id\",\n",
    "        \"customer_id\": \"s.customer_id\",\n",
    "        \"status\": \"s.status\",\n",
    "        \"credit_limit\": \"s.credit_limit\",\n",
    "        \"valid_from\": current_timestamp(),\n",
    "        \"valid_to\": lit(None),  # Set valid_to as NULL for current records\n",
    "        \"is_current\": lit(True)  # Mark the new record as current\n",
    "    }\n",
    ").execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3c4d9750-629c-453d-b54f-db7b952119d6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.read.table(target_table_name).display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "43e03cc4-20fb-4c1d-8579-a124989f8161",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.read.table(target_table_name).display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "edf73eed-dad2-4806-ad0d-3fbf2006a8a3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "tracking",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
